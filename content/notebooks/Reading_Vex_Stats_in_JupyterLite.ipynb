{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": [
        {
          "file_id": "1bufmDPEysUkvDUQHsVwH8xD9aogghB5n",
          "timestamp": 1752023546107
        },
        {
          "file_id": "1xvS_UzSbI6toJymoT9tfD7bQYqs-xDDG",
          "timestamp": 1746744600281
        }
      ],
      "authorship_tag": "ABX9TyN00W1Rfbcm6XPJoUSlH4rx"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Reading VEX Stats\r\n\r\nThis notebook is a demonstration of using the RobotEvents.com API to retrieve and analyse robotics competition data.\r\n\r\n[API Documentation](https://www.robotevents.com/api/v2)\r\n\r\n[Terms of use for robotevents.com](https://www.vexrobotics.com/terms-of-use)\r\n\r\n## Setup\r\n\r\nThis first cell will get everything set up, including our Data Dunkers API token. You may need to set up your own token by [requesting access](https://www.robotevents.com/api/v2/accessRequest/create) and then [creating a new token](https://www.robotevents.com/api/v2/tokens).",
      "metadata": {
        "id": "QRF_Gv6seZC_"
      }
    },
    {
      "cell_type": "code",
      "source": "token = ''\n\nimport piplite, pyodide_http, pyodide\nawait piplite.install(['pandas', 'plotly', 'nbformat', 'statsmodels'])\npyodide_http.patch_all()\nimport requests\nimport pandas as pd\nimport plotly.express as px\n#df = pd.read_csv(pyodide.http.open_url('https://docs.google.com/spreadsheets/d/1KeUkR2qpsaFdU2Lvks79vju22fJNzFB-iGfGUxmPQHI/export?format=csv'))\n\nheaders = {'Authorization': f'Bearer {token}'}\nprint('setup completed')",
      "metadata": {
        "id": "-blWDHiXegZV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Teams\r\n\r\nNow that we have everything set up, we can get data about an individual team.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "team_number = '7410X'\n\nteam_data = requests.get(f'https://www.robotevents.com/api/v2/teams?number={team_number}', headers=headers).json()\nteam_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "team_data['data'][0]['organization']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also get event data.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "event_code = 'RE-V5RC-24-6445'\n\nevent_data = requests.get(f'https://www.robotevents.com/api/v2/events?code={event_code}', headers=headers).json()\nevent_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We need to do some parsing to flatten that [JSON](https://en.wikipedia.org/wiki/JSON) so we can create a [pandas dataframe](https://en.wikipedia.org/wiki/Pandas_(software)#DataFrames).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "records = []\nfor e in event_data['data']:\n  record = {\n      'id': e.get('id'),\n      'sku': e.get('sku'),\n      'name': e.get('name'),\n      'start': e.get('start'),\n      'end': e.get('end'),\n      'season_id': e.get('season', {}).get('id'),\n      'season_name': e.get('season', {}).get('name'),\n      'program_id': e.get('program', {}).get('id'),\n      'program_name': e.get('program', {}).get('name'),\n      'program_code': e.get('program', {}).get('code'),\n      'venue': e.get('location', {}).get('venue'),\n      'city': e.get('location', {}).get('city'),\n      'region': e.get('location', {}).get('region'),\n      'country': e.get('location', {}).get('country'),\n      'lat': e.get('location', {}).get('coordinates', {}).get('lat'),\n      'lon': e.get('location', {}).get('coordinates', {}).get('lon'),\n      'level': e.get('level'),\n      'ongoing': e.get('ongoing'),\n      'awards_finalized': e.get('awards_finalized'),\n      'divisions': ', '.join([d.get('name', '') for d in e.get('divisions', [])]),  # join division names if there are multiple\n    }\n  records.append(record)\ndf = pd.DataFrame(records)\ndf",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Alternatively, we could use `json_normalize` on the columns that contain dictionaries or lists. Remove the `'''` lines to run this cell if you'd like, but your resulting dataframe may be messier.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "'''\ndf = pd.DataFrame(event_data['data'])\n\nfor column in df.columns:\n  if type(df[column][0]) == dict and column != 'locations': # we'll skip flatening the locations column\n    temp_df = pd.json_normalize(df[column]).add_prefix(column + '_')\n    df = pd.concat([df, temp_df], axis=1)\n    df = df.drop(columns=[column])\n  elif type(df[column][0]) == list:\n    temp_df = pd.json_normalize(df[column]).apply(lambda x: x[0])\n    temp_df = temp_df.add_prefix(column + '_')\n    df = pd.concat([df, temp_df], axis=1)\n    df = df.drop(columns=[column])\ndf\n'''",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's have a look at the column names.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.columns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can visualize some data with [Plotly Express](https://plotly.com/python/plotly-express/).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "px.scatter(df, x='lon', y='lat', color='season_name', title='VEX Events')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Seasons\r\n\r\nWe can also get data about the competition seaso and convert it into a flattened dataframe.s.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "seasons = requests.get('https://www.robotevents.com/api/v2/seasons?per_page=250', headers=headers).json()\ntemp_df = pd.DataFrame(seasons['data'])\nseasons_data = pd.concat([temp_df, pd.json_normalize(temp_df['program']).add_prefix('program' + '_')], axis=1).drop(columns=['program'])\nseasons_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's look at just V5 (`'program_id' == 1`).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "seasons_data[seasons_data['program_id'] == 1]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can use the API again to pull data about events from last season (`'id' == 190`).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "id = 190\n\nevents = []\npage = 1\n\nwhile True:\n  r = requests.get(f'https://www.robotevents.com/api/v2/seasons/{id}/events?page={page}&per_page=250', headers=headers).json()\n  events.extend(r['data'])\n  if r['meta']['next_page_url']:\n    page += 1\n  else:\n    break\nevents_data = pd.DataFrame(events)\nevents_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "And we can expand some of the columns that contain dictionaries.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "events_data = pd.DataFrame(events)\n\ncolumns = ['season', 'program', 'location']\nfor column in columns:\n  temp_df = pd.json_normalize(events_data[column]).add_prefix(column + '_')\n  events_data = pd.concat([events_data, temp_df], axis=1)\nevents_data = events_data.drop(columns=columns)\n\nevents_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Hopefully this is a good start for data science with [RobotEvents.com](https://RobotEvents.com) data.",
      "metadata": {}
    }
  ]
}